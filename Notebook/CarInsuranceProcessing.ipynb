{"nbformat_minor": 2, "cells": [{"execution_count": 1, "cell_type": "code", "source": "import matplotlib.pyplot as plt # plotting\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#from pyspark.sql import Row\nfrom pyspark.sql import SQLContext\n#from pyspark import SparkFiles\nfrom pyspark.sql.types import *\nimport datetime\nimport pyspark.sql.functions as f\n#from sklearn.model_selection import StratifiedShuffleSplit\nfrom pyspark.ml.classification import LogisticRegression, RandomForestClassifier\nfrom pyspark.ml.regression import LinearRegression, GBTRegressor\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.feature import *\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Starting Spark application\n"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>3</td><td>application_1599211381522_0148</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-sirags.yzwod5meikrurjluirb4xzsm2h.bx.internal.cloudapp.net:8088/proxy/application_1599211381522_0148/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn3-sirags.yzwod5meikrurjluirb4xzsm2h.bx.internal.cloudapp.net:30060/node/containerlogs/container_1599211381522_0148_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "SparkSession available as 'spark'.\n"}], "metadata": {"cell_status": {"execute_time": {"duration": 757.450927734375, "end_time": 1599477962080.422}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 2, "cell_type": "code", "source": "#get SQL context for the current Spark session to run SQL read\nsqlContext = SQLContext(sc)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 37.89501953125, "end_time": 1599477962129.226}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "*<font size=\"5\"> Replace ADLS_NAME in the cell below with the ADLS Storage name you just created </font>*", "cell_type": "markdown", "metadata": {}}, {"execution_count": 3, "cell_type": "code", "source": "# Location of training data\nins_train_file_loc = \"abfs://data@<ADLS NAME>.dfs.core.windows.net/car_insurance_claim.csv\"\n# Set model storage directory path. This is where models will be saved. Replace the <ADLS_NAME> with the actual ADLS Name\nCatModelLoc = \"abfs://models@<ADLS_NAME>.dfs.core.windows.net/CatMod/\"; # The last backslash is needed;\nIntModelLoc = \"abfs://models@<ADLS_NAME>.dfs.core.windows.net/IntMod/\"\nPipelineLoc = \"abfs://models@<ADLS_NAME>.dfs.core.windows.net/PipelineMod/\"", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 34.60986328125, "end_time": 1599477962174.827}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 4, "cell_type": "code", "source": "# Let's make sure that we got the locations correct\nprint(ins_train_file_loc)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "abfs://data@dlinsure.dfs.core.windows.net/car_insurance_claim.csv"}], "metadata": {"cell_status": {"execute_time": {"duration": 46.68896484375, "end_time": 1599477962262.106}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "\n**<font size=\"11\">READ THE CSV AND CLEAN THE DATA </font>**\n\n*<font size=\"5\">we use sqlcontext to read the file to infer the schema as it is in the csv</font>*\n", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 5, "cell_type": "code", "source": "ClaimData = sqlContext.read.csv(ins_train_file_loc, header=True, inferSchema=True)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 9534.807861328125, "end_time": 1599477971816.13}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 6, "cell_type": "code", "source": "ClaimData.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- ID: integer (nullable = true)\n |-- BIRTH: string (nullable = true)\n |-- AGE: integer (nullable = true)\n |-- HOMEKIDS: integer (nullable = true)\n |-- YOJ: integer (nullable = true)\n |-- INCOME: string (nullable = true)\n |-- MSTATUS: string (nullable = true)\n |-- GENDER: string (nullable = true)\n |-- EDUCATION: string (nullable = true)\n |-- OCCUPATION: string (nullable = true)\n |-- TRAVTIME: integer (nullable = true)\n |-- BLUEBOOK: string (nullable = true)\n |-- TIF: integer (nullable = true)\n |-- CAR_TYPE: string (nullable = true)\n |-- OLDCLAIM: string (nullable = true)\n |-- CLM_FREQ: integer (nullable = true)\n |-- MVR_PTS: integer (nullable = true)\n |-- CLM_AMT: string (nullable = true)\n |-- CAR_AGE: integer (nullable = true)\n |-- CLAIM_FLAG: integer (nullable = true)"}], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 244.47998046875, "end_time": 1599477972071.548}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 7, "cell_type": "code", "source": "#Display the columns and see how the columns are processed\npd.DataFrame(ClaimData.take(5), columns=ClaimData.columns)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "          ID      BIRTH  AGE  HOMEKIDS  YOJ    INCOME MSTATUS GENDER  \\\n0   63581743  16-Mar-39   60         0   11  $67,349     z_No      M   \n1  132761049  21-Jan-56   43         0   11  $91,449     z_No      M   \n2  921317019  18-Nov-51   48         0   11  $52,881     z_No      M   \n3  727598473   5-Mar-64   35         1   10  $16,039      Yes    z_F   \n4  450221861   5-Jun-48   51         0   14      None     Yes      M   \n\n       EDUCATION     OCCUPATION  TRAVTIME  BLUEBOOK  TIF CAR_TYPE  OLDCLAIM  \\\n0            PhD   Professional        14  $14,230    11  Minivan   $4,461    \n1  z_High School  z_Blue Collar        22  $14,940     1  Minivan       $0    \n2      Bachelors        Manager        26  $21,970     1      Van       $0    \n3  z_High School       Clerical         5   $4,010     4    z_SUV  $38,690    \n4   <High School  z_Blue Collar        32  $15,440     7  Minivan       $0    \n\n   CLM_FREQ  MVR_PTS CLM_AMT  CAR_AGE  CLAIM_FLAG  \n0         2        3     $0        18           0  \n1         0        0     $0         1           0  \n2         0        2     $0        10           0  \n3         2        3     $0        10           0  \n4         0        0     $0         6           0"}], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 763.451904296875, "end_time": 1599477972845.771}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 8, "cell_type": "code", "source": "#Make the data more readable\nClaimData_df=ClaimData.withColumnRenamed(\"YOJ\",\"YearsOnJob\")\\\n            .withColumnRenamed(\"TRAVTIME\",\"Travel_time\")\\\n            .withColumnRenamed(\"TIF\",\"Time_In_Force\")\\\n            .withColumnRenamed(\"OLDCLAIM\",\"OLDCLAIM_AMT\")\\\n            .withColumnRenamed(\"CLM_FREQ\",\"CLAIM_FREQ\")\\\n            .withColumnRenamed(\"CLM_AMT\",\"TARGET_CLAIM\") \\\n            .withColumnRenamed(\"CLAIM_FLAG\",\"CRASH_FLAG\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 256.36083984375, "end_time": 1599477973112.197}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 9, "cell_type": "code", "source": "#Display DUplicate Data\nClaimData_df.groupBy(ClaimData_df.columns)\\\n            .count()\\\n            .where(f.col('count') > 1)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "DataFrame[ID: int, BIRTH: string, AGE: int, HOMEKIDS: int, YearsOnJob: int, INCOME: string, MSTATUS: string, GENDER: string, EDUCATION: string, OCCUPATION: string, Travel_time: int, BLUEBOOK: string, Time_In_Force: int, CAR_TYPE: string, OLDCLAIM_AMT: string, CLAIM_FREQ: int, MVR_PTS: int, TARGET_CLAIM: string, CAR_AGE: int, CRASH_FLAG: int, count: bigint]"}], "metadata": {"cell_status": {"execute_time": {"duration": 745.7861328125, "end_time": 1599477973871.747}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "**<fontsize='10'>we have made sure columns are readable. Now let us clean the data and make sure there are no nulls or unnecessary columns</font>**", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 10, "cell_type": "code", "source": "#Clean the string data and remove unnecessary characters\nClaimData_df=ClaimData_df.withColumn(\"INCOME\", f.regexp_replace(f.col(\"INCOME\"), \"[$#,]\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"BLUEBOOK\", f.regexp_replace(f.col(\"BLUEBOOK\"), \"[$#,]\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"OLDCLAIM_AMT\", f.regexp_replace(f.col(\"OLDCLAIM_AMT\"), \"[$#,]\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"TARGET_CLAIM\", f.regexp_replace(f.col(\"TARGET_CLAIM\"), \"[$#,]\", \"\"))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 253.81591796875, "end_time": 1599477974137.043}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 11, "cell_type": "code", "source": "ClaimData_df=ClaimData_df.withColumn(\"MSTATUS\", f.regexp_replace(f.col(\"MSTATUS\"), \"z_\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"GENDER\", f.regexp_replace(f.col(\"GENDER\"), \"z_\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"EDUCATION\", f.regexp_replace(f.col(\"EDUCATION\"), \"[z_<]\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"OCCUPATION\", f.regexp_replace(f.col(\"OCCUPATION\"), \"z_\", \"\"))\nClaimData_df=ClaimData_df.withColumn(\"CAR_TYPE\", f.regexp_replace(f.col(\"CAR_TYPE\"), \"z_\", \"\"))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 242.8271484375, "end_time": 1599477974392.509}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 12, "cell_type": "code", "source": "#Trim to remove all extra whitespaces so casting to integer is easy\nClaimData_df=ClaimData_df.withColumn(\"INCOME\", f.trim(ClaimData_df.INCOME))\nClaimData_df=ClaimData_df.withColumn(\"BLUEBOOK\", f.trim(ClaimData_df.BLUEBOOK))\nClaimData_df=ClaimData_df.withColumn(\"OLDCLAIM_AMT\", f.trim(ClaimData_df.OLDCLAIM_AMT))\nClaimData_df=ClaimData_df.withColumn(\"TARGET_CLAIM\", f.trim(ClaimData_df.TARGET_CLAIM))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 242.005859375, "end_time": 1599477974645.493}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 13, "cell_type": "code", "source": "#Drop all null values from all rows\nClaimData_df = ClaimData_df.na.drop()", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 247.702880859375, "end_time": 1599477974905.998}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 14, "cell_type": "code", "source": "#Let's adjust the datatypes to make sure we assign the right dayatypes\nClaimData_df=ClaimData_df.withColumn('INCOME',ClaimData_df[\"INCOME\"].cast(IntegerType()))\nClaimData_df=ClaimData_df.withColumn('BLUEBOOK',ClaimData_df[\"BLUEBOOK\"].cast(IntegerType()))\nClaimData_df=ClaimData_df.withColumn('OLDCLAIM_AMT',ClaimData_df[\"OLDCLAIM_AMT\"].cast(IntegerType()))\nClaimData_df=ClaimData_df.withColumn('TARGET_CLAIM',ClaimData_df[\"TARGET_CLAIM\"].cast(IntegerType()))\nClaimData_df=ClaimData_df.withColumn('CRASH_FLAG',ClaimData_df[\"CRASH_FLAG\"].cast(IntegerType()))", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 255.5498046875, "end_time": 1599477975172.771}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 15, "cell_type": "code", "source": "#check final schema\nClaimData_df.printSchema()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- ID: integer (nullable = true)\n |-- BIRTH: string (nullable = true)\n |-- AGE: integer (nullable = true)\n |-- HOMEKIDS: integer (nullable = true)\n |-- YearsOnJob: integer (nullable = true)\n |-- INCOME: integer (nullable = true)\n |-- MSTATUS: string (nullable = true)\n |-- GENDER: string (nullable = true)\n |-- EDUCATION: string (nullable = true)\n |-- OCCUPATION: string (nullable = true)\n |-- Travel_time: integer (nullable = true)\n |-- BLUEBOOK: integer (nullable = true)\n |-- Time_In_Force: integer (nullable = true)\n |-- CAR_TYPE: string (nullable = true)\n |-- OLDCLAIM_AMT: integer (nullable = true)\n |-- CLAIM_FREQ: integer (nullable = true)\n |-- MVR_PTS: integer (nullable = true)\n |-- TARGET_CLAIM: integer (nullable = true)\n |-- CAR_AGE: integer (nullable = true)\n |-- CRASH_FLAG: integer (nullable = true)"}], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 34.55810546875, "end_time": 1599477975220.962}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 16, "cell_type": "code", "source": "#describe the numeric data to find any anomalies\nnumeric_features=[t[0] for t in ClaimData_df.dtypes if t[1]== 'int']\nClaimData_df.select(numeric_features).describe().toPandas().transpose()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "                   0                    1                   2       3  \\\nsummary        count                 mean              stddev     min   \nID              8091  4.975425108930911E8  2.85190360837908E8  246910   \nAGE             8091   44.691138301816835   8.643031693932897      16   \nHOMEKIDS        8091    0.739216413298727  1.1276799767862071       0   \nYearsOnJob      8091   10.440489432703004    4.17340593998557       0   \nINCOME          8091    57787.98207885305   44070.69398819117       0   \nTravel_time     8091    33.61055493758497  15.821258478790469       5   \nBLUEBOOK        8091   15173.859844271412   8071.717088459349    1500   \nTime_In_Force   8091    5.333951303917933   4.128523345661906       1   \nOLDCLAIM_AMT    8091   4027.5213199851687   8791.546766776568       0   \nCLAIM_FREQ      8091   0.7911259424051416  1.1504286750162802       0   \nMVR_PTS         8091   1.7210480781114819  2.1791064700240286       0   \nTARGET_CLAIM    8091   1503.4407366209368   4631.689518986392       0   \nCAR_AGE         8091    7.896180941787171   5.586257993259534      -3   \nCRASH_FLAG      8091  0.26807563959955505  0.4429845873018242       0   \n\n                       4  \nsummary              max  \nID             999926368  \nAGE                   81  \nHOMEKIDS               5  \nYearsOnJob            23  \nINCOME            367030  \nTravel_time          142  \nBLUEBOOK           65970  \nTime_In_Force         25  \nOLDCLAIM_AMT       57037  \nCLAIM_FREQ             5  \nMVR_PTS               13  \nTARGET_CLAIM      123247  \nCAR_AGE               28  \nCRASH_FLAG             1"}], "metadata": {"cell_status": {"execute_time": {"duration": 3362.0009765625, "end_time": 1599477978639.824}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 17, "cell_type": "code", "source": "#Let's drop that row that shows has negative car age\nClaimData_df=ClaimData_df.where(ClaimData_df.CAR_AGE!=-3)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 237.809814453125, "end_time": 1599477978891.509}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "*<fontsize='5'> Let us examine the data *</font> ", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 30.010986328125, "end_time": 1598595370818.252}}, "editable": true, "deletable": true}}, {"execution_count": 18, "cell_type": "code", "source": "# Scatter and density plots\ndef plotScatterMatrix(df, plotSize, textSize):\n    numeric_features=[t[0] for t in df.dtypes if t[1]== 'int']\n    df=df.select(numeric_features).toPandas() # keep only numerical columns\n    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n    n = len(df.columns)\n    columnNames = list(df)\n    if n > 10: # reduce the number of columns for matrix inversion of kernel density plots\n        columnNames = columnNames[:10]\n    df = df[columnNames]\n    ax = pd.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize])\n    corrs = df.corr().values\n    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n        v = ax[i, 0]\n        v.yaxis.label.set_rotation(0)\n        v.yaxis.label.set_ha('right')\n        v.set_yticks(())\n        h = ax[9, i]\n        h.xaxis.label.set_rotation(90)    \n        h.set_xticks(())\n        ax[i, j].annotate('%.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n    plt.suptitle('Scatter and Density Plot')\n    plt.show()", "outputs": [], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 42.7880859375, "end_time": 1599477978948.837}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 19, "cell_type": "code", "source": "plotScatterMatrix(ClaimData_df, 12, 15)", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "88f4cef1c81a46c7ab14cf13a2e1634e"}}, "metadata": {}}, {"output_type": "stream", "name": "stdout", "text": "<string>:11: FutureWarning: pandas.scatter_matrix is deprecated. Use pandas.plotting.scatter_matrix instead\n"}], "metadata": {"cell_status": {"execute_time": {"duration": 25648.30517578125, "end_time": 1599478004692.266}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "<fontsize='8'> we will keep all the features for now because they do not seem to be strongly correlated </font>", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"source": "<fontsize='12'> *let us prepare the columds for features by converting the string type features to categorical vectors*</font>", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 20, "cell_type": "code", "source": "y_udf=f.udf(lambda y: \"No\" if y==0 else \"Yes\", StringType())\nnew_df=ClaimData_df.withColumn(\"CRASH_FLAGG\", y_udf('CRASH_FLAG')).drop(\"CRASH_FLAG\")\nClaimData_df.checkpoint", "outputs": [{"output_type": "stream", "name": "stdout", "text": "<bound method DataFrame.checkpoint of DataFrame[ID: int, BIRTH: string, AGE: int, HOMEKIDS: int, YearsOnJob: int, INCOME: int, MSTATUS: string, GENDER: string, EDUCATION: string, OCCUPATION: string, Travel_time: int, BLUEBOOK: int, Time_In_Force: int, CAR_TYPE: string, OLDCLAIM_AMT: int, CLAIM_FREQ: int, MVR_PTS: int, TARGET_CLAIM: int, CAR_AGE: int, CRASH_FLAG: int]>"}], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 246.203125, "end_time": 1599478004949.75}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 21, "cell_type": "code", "source": "new_df=new_df.withColumnRenamed(\"CRASH_FLAGG\",\"CRASH_FLAG\")", "outputs": [], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 31.077880859375, "end_time": 1599478004991.28}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 48, "cell_type": "code", "source": "numeric_features=[t[0] for t in new_df.dtypes if t[1]== 'int']\nCategoric_features=[t[0] for t in new_df.dtypes if t[1]== 'string']\nprint(Categoric_features)\nprint(numeric_features)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "['BIRTH', 'MSTATUS', 'GENDER', 'EDUCATION', 'OCCUPATION', 'CAR_TYPE', 'CRASH_FLAG']\n['ID', 'AGE', 'HOMEKIDS', 'YearsOnJob', 'INCOME', 'Travel_time', 'BLUEBOOK', 'Time_In_Force', 'OLDCLAIM_AMT', 'CLAIM_FREQ', 'MVR_PTS', 'TARGET_CLAIM', 'CAR_AGE']"}], "metadata": {"cell_status": {"execute_time": {"duration": 36.357177734375, "end_time": 1599478732282.858}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 49, "cell_type": "code", "source": "#Remove the target fields from feature list\nnumeric_features.remove('TARGET_CLAIM')\nCategoric_features.remove('CRASH_FLAG')\n#Also remove the features that we know are too unique to make a difference\nCategoric_features.remove('BIRTH')\nnumeric_features.remove('ID')", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 29.18310546875, "end_time": 1599478732513.155}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 50, "cell_type": "code", "source": "stages = []\n\nfor categoricalCol in Categoric_features:\n    stringIndexer = StringIndexer() \\\n                    .setInputCol (categoricalCol) \\\n                    .setOutputCol (categoricalCol + '_Index') \\\n                    .setHandleInvalid (\"skip\")\n    stages += [stringIndexer]\n        \n\nstages", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[StringIndexer_db9f603b42c6, StringIndexer_8dda92dd1d31, StringIndexer_f3eb3eb955ae, StringIndexer_45a5d5c76658, StringIndexer_db6a76972b36]"}], "metadata": {"cell_status": {"execute_time": {"duration": 241.465087890625, "end_time": 1599478732882.656}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 51, "cell_type": "code", "source": "for categoricalCol in Categoric_features:\n    encoder = OneHotEncoderEstimator() \\\n                .setInputCols ([categoricalCol + '_Index']) \\\n                .setOutputCols ([categoricalCol + \"classVec\"])\n    stages += [encoder]\n    \nstages", "outputs": [{"output_type": "stream", "name": "stdout", "text": "[StringIndexer_db9f603b42c6, StringIndexer_8dda92dd1d31, StringIndexer_f3eb3eb955ae, StringIndexer_45a5d5c76658, StringIndexer_db6a76972b36, OneHotEncoderEstimator_8dc3813bca87, OneHotEncoderEstimator_4543c1e28006, OneHotEncoderEstimator_22868e3c800b, OneHotEncoderEstimator_6a5ec6d9539b, OneHotEncoderEstimator_0ea8e47e75b8]"}], "metadata": {"cell_status": {"execute_time": {"duration": 239.220947265625, "end_time": 1599478733132.459}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 52, "cell_type": "code", "source": "label_stringIdx = StringIndexer(inputCol = 'CRASH_FLAG', outputCol = 'label')\nstages += [label_stringIdx]", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 241.797119140625, "end_time": 1599478733385.372}}, "editable": true, "collapsed": true, "deletable": true}}, {"execution_count": 53, "cell_type": "code", "source": "assemblerInputs = [c + \"classVec\" for c in Categoric_features] + numeric_features", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 31.0380859375, "end_time": 1599478733577.392}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 55, "cell_type": "code", "source": "assembler = VectorAssembler()\\\n            .setInputCols(assemblerInputs) \\\n            .setOutputCol(\"vec_features\") \nstages += [assembler]", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 235.010986328125, "end_time": 1599478734179}}, "editable": true, "collapsed": true, "deletable": true}}, {"execution_count": 56, "cell_type": "code", "source": "scaler = StandardScaler()\\\n         .setInputCol(\"vec_features\") \\\n         .setOutputCol(\"features\") \nstages += [scaler]", "outputs": [], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 234.661865234375, "end_time": 1599478734487.097}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 57, "cell_type": "code", "source": "pipeline = Pipeline(stages = stages)\npipelineModel = pipeline.fit(new_df)\n\ntestdf=pipelineModel.transform(new_df)", "outputs": [], "metadata": {"scrolled": true, "cell_status": {"execute_time": {"duration": 9298.93798828125, "end_time": 1599478743796.119}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 58, "cell_type": "code", "source": "pipelineModel.write().overwrite().save(PipelineLoc)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 11317.72119140625, "end_time": 1599478755123.156}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "<font size='5'> * now let us build and run the models to predict whether there is going to be a crash ('CRASH_FLAG') * </font>", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 59, "cell_type": "code", "source": "#split the rows into 70% training and 30% testing sets\nsplits=testdf.randomSplit([0.7, 0.3], 2018)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 264.182861328125, "end_time": 1599478755397.454}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 60, "cell_type": "code", "source": "train_df=splits[0]\ntest_df=splits[1]\nprint(train_df.count())\nprint(test_df.count())", "outputs": [{"output_type": "stream", "name": "stdout", "text": "5631\n2459"}], "metadata": {"scrolled": false, "cell_status": {"execute_time": {"duration": 29371.47998046875, "end_time": 1599478784781.772}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 61, "cell_type": "code", "source": "#use Binomial Logistic regression to predict \"CRASH_FLAG\"\n\nlr = LogisticRegression(featuresCol= 'features', labelCol='label', maxIter=10)\n# Fit the model\nlrModel = lr.fit(train_df)\n\nb= np.sort(lrModel.coefficients)\nplt.plot(b)\nplt.ylabel('Beta Coefficients')\nplt.show()", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "5b2362bcda6b4594ab669b322d1e22b5"}}, "metadata": {}}], "metadata": {"cell_status": {"execute_time": {"duration": 57502.9501953125, "end_time": 1599478842306.018}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 62, "cell_type": "code", "source": "#run the model to predict and measure the accuracy of model\npredictions=lrModel.transform(test_df)\npredictions.select('label','features','rawPrediction','prediction','probability').toPandas().head(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "   label                                           features  \\\n0    0.0  (2.04038299006, 2.01380935057, 0.0, 0.0, 2.640...   \n1    0.0  (2.04038299006, 0.0, 2.0041819363, 0.0, 0.0, 0...   \n2    1.0  (2.04038299006, 0.0, 2.0041819363, 0.0, 0.0, 0...   \n3    0.0  (2.04038299006, 2.01380935057, 0.0, 0.0, 2.640...   \n4    0.0  (2.04038299006, 0.0, 0.0, 2.20732455419, 0.0, ...   \n\n                       rawPrediction  prediction  \\\n0  [0.353134344448, -0.353134344448]         0.0   \n1    [2.11544048216, -2.11544048216]         0.0   \n2  [0.206407057154, -0.206407057154]         0.0   \n3    [2.18973547341, -2.18973547341]         0.0   \n4    [2.26485516621, -2.26485516621]         0.0   \n\n                         probability  \n0   [0.587377442364, 0.412622557636]  \n1     [0.89239487877, 0.10760512123]  \n2   [0.551419338535, 0.448580661465]  \n3   [0.899323958629, 0.100676041371]  \n4  [0.905924231399, 0.0940757686007]"}], "metadata": {"cell_status": {"execute_time": {"duration": 15311.566162109375, "end_time": 1599478857629.479}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 63, "cell_type": "code", "source": "evaluator = BinaryClassificationEvaluator()\nprint('Test Area Under ROC', evaluator.evaluate(predictions))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "('Test Area Under ROC', 0.7563209593060258)"}], "metadata": {"cell_status": {"execute_time": {"duration": 15313.989013671875, "end_time": 1599478872953.905}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 64, "cell_type": "code", "source": "#Use random forest classifiers to predict CRASH_FLAG\nRF = RandomForestClassifier(featuresCol = 'features', labelCol = 'label')\nrfModel = RF.fit(train_df)\npredictions_rf = rfModel.transform(test_df)\npredictions_rf.select('label', 'features','rawPrediction', 'prediction', 'probability').show(10)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+-----+--------------------+--------------------+----------+--------------------+\n|label|            features|       rawPrediction|prediction|         probability|\n+-----+--------------------+--------------------+----------+--------------------+\n|  0.0|(28,[0,1,4,9,12,1...|[13.5215237297247...|       0.0|[0.67607618648623...|\n|  0.0|(28,[0,2,6,13,17,...|[16.5917439820685...|       0.0|[0.82958719910342...|\n|  1.0|(28,[0,2,6,14,17,...|[10.1372360342537...|       0.0|[0.50686180171268...|\n|  0.0|(28,[0,1,4,8,12,1...|[16.8987925076505...|       0.0|[0.84493962538252...|\n|  0.0|(28,[0,3,6,13,17,...|[17.4124403360897...|       0.0|[0.87062201680448...|\n|  0.0|(28,[0,1,2,5,12,1...|[10.9053031417032...|       0.0|[0.54526515708516...|\n|  0.0|(28,[0,2,5,13,17,...|[15.8498946532182...|       0.0|[0.79249473266091...|\n|  1.0|(28,[1,3,8,16,17,...|[16.4047413878919...|       0.0|[0.82023706939459...|\n|  0.0|(28,[0,4,9,13,17,...|[16.0338304493869...|       0.0|[0.80169152246934...|\n|  0.0|(28,[1,2,11,12,17...|[9.76454229054585...|       1.0|[0.48822711452729...|\n+-----+--------------------+--------------------+----------+--------------------+\nonly showing top 10 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 45452.614990234375, "end_time": 1599478918416.727}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 65, "cell_type": "code", "source": "print('Test Area Under ROC', evaluator.evaluate(predictions_rf))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "('Test Area Under ROC', 0.7524760811327967)"}], "metadata": {"cell_status": {"execute_time": {"duration": 15301.24609375, "end_time": 1599478933729.223}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "*<font size ='8'> Now let us filter the data to pick all the rows that have had a crash to predict what their claim amount would be </font>*", "cell_type": "markdown", "metadata": {"cell_status": {"execute_time": {"duration": 40.718017578125, "end_time": 1598595851580.211}}, "editable": true, "deletable": true}}, {"execution_count": 66, "cell_type": "code", "source": "tempdf = testdf.filter(testdf.CRASH_FLAG==\"Yes\")", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 262.85498046875, "end_time": 1599478934007.741}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 67, "cell_type": "code", "source": "splits=tempdf.randomSplit([0.7, 0.3], 2018)\ntrain_df=splits[0]\ntest_df=splits[1]", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 236.44482421875, "end_time": 1599478934254.177}}, "editable": true, "collapsed": false, "deletable": true}}, {"source": "<bold> Ideally, you would tune the Parameters to see which ones have the best impact and choose the best model. We're not doing that here since it takes time and is out of scope for this demonstration </bold>", "cell_type": "markdown", "metadata": {"editable": true, "deletable": true}}, {"execution_count": 68, "cell_type": "code", "source": "#Run Linear Regression to predict 'TARGET_CLAIM'\nclaims = LinearRegression(featuresCol='features', labelCol='TARGET_CLAIM', maxIter=5, regParam=0.3)\nclaim_model = claims.fit(train_df)\n\nb= np.sort(claim_model.coefficients)\nplt.plot(b)\nplt.ylabel('Beta Coefficients')\nplt.show()", "outputs": [{"output_type": "display_data", "data": {"application/vnd.jupyter.widget-view+json": {"model_id": "423113ad1d3b42f78886f38cecd58fc6"}}, "metadata": {}}], "metadata": {"cell_status": {"execute_time": {"duration": 71564.28295898438, "end_time": 1599479005838.582}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 69, "cell_type": "code", "source": "claim_pred = claim_model.transform(test_df)\nclaim_pred.select('CRASH_FLAG','TARGET_CLAIM','features','prediction').show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+------------+--------------------+------------------+\n|CRASH_FLAG|TARGET_CLAIM|            features|        prediction|\n+----------+------------+--------------------+------------------+\n|       Yes|        5324|(28,[0,2,7,17,19,...| 6339.327476900963|\n|       Yes|        6882|(28,[2,6,14,17,18...| 5134.534975649354|\n|       Yes|        6907|(28,[0,1,2,5,12,1...|2949.2306128687014|\n|       Yes|        1125|(28,[3,6,17,19,20...| 7667.561400494532|\n|       Yes|        4259|(28,[1,2,6,15,17,...| 4565.712072418948|\n|       Yes|       22244|(28,[3,5,16,17,19...| 7223.038489286063|\n|       Yes|        3085|(28,[1,2,11,12,17...| 5076.875329152249|\n|       Yes|        2091|(28,[1,2,11,12,17...| 5576.430390951745|\n|       Yes|        6005|(28,[0,1,3,7,15,1...|4646.4551111062765|\n|       Yes|       28706|(28,[1,4,9,13,17,...| 5258.461218819752|\n|       Yes|        4373|(28,[1,3,7,12,17,...| 5382.225994645652|\n|       Yes|       20883|(28,[2,5,16,17,19...|7112.5516035881255|\n|       Yes|        3989|(28,[3,7,16,17,19...| 6205.454263386084|\n|       Yes|        3311|(28,[0,1,2,11,12,...| 5114.139181953403|\n|       Yes|       25695|(28,[2,5,14,17,18...| 6056.558014569605|\n|       Yes|        5802|(28,[1,3,5,12,17,...| 6238.860131015387|\n|       Yes|        5982|(28,[1,3,11,12,17...| 5252.489461444654|\n|       Yes|        5396|(28,[0,3,7,14,17,...|3944.6644151244177|\n|       Yes|        1022|(28,[0,1,2,10,12,...| 5573.503424654662|\n|       Yes|        5110|(28,[0,3,10,14,17...| 4476.656571014512|\n+----------+------------+--------------------+------------------+\nonly showing top 20 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 15306.705078125, "end_time": 1599479021156.326}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 70, "cell_type": "code", "source": "regevaluator = RegressionEvaluator()\nprint('Test Area Under ROC', regevaluator.evaluate(claim_pred))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "('Test Area Under ROC', 5401.871214812071)"}], "metadata": {"cell_status": {"execute_time": {"duration": 15514.215087890625, "end_time": 1599479036680.295}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 71, "cell_type": "code", "source": "gbt = GBTRegressor(featuresCol='features', labelCol='TARGET_CLAIM', maxIter=5)\ngbt_model = gbt.fit(train_df)\ngbt_predictions = gbt_model.transform(test_df)\ngbt_predictions.select('prediction', 'TARGET_CLAIM', 'features').show(5)", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------------------+------------+--------------------+\n|        prediction|TARGET_CLAIM|            features|\n+------------------+------------+--------------------+\n|  4759.80861919182|        5324|(28,[0,2,7,17,19,...|\n|  3776.46193528764|        6882|(28,[2,6,14,17,18...|\n|4938.9403517537285|        6907|(28,[0,1,2,5,12,1...|\n|  6755.23963954104|        1125|(28,[3,6,17,19,20...|\n|3432.6857360226772|        4259|(28,[1,2,6,15,17,...|\n+------------------+------------+--------------------+\nonly showing top 5 rows"}], "metadata": {"cell_status": {"execute_time": {"duration": 45522.2890625, "end_time": 1599479082215.645}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 72, "cell_type": "code", "source": "print('Test Area Under ROC', regevaluator.evaluate(gbt_predictions))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "('Test Area Under ROC', 5647.310157530764)"}], "metadata": {"cell_status": {"execute_time": {"duration": 15300.12890625, "end_time": 1599479097526.774}}, "editable": true, "collapsed": false, "deletable": true}}, {"execution_count": 73, "cell_type": "code", "source": "#Persist the model to the containers to use them later\nlrModel.write().overwrite().save(CatModelLoc)\ngbt_model.write().overwrite().save(IntModelLoc)", "outputs": [], "metadata": {"cell_status": {"execute_time": {"duration": 2280.2919921875, "end_time": 1599479099817.453}}, "editable": true, "collapsed": false, "deletable": true}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}